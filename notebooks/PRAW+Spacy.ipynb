{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T20:35:12.722359Z",
     "start_time": "2021-07-11T20:35:11.311594Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pmaw import PushshiftAPI\n",
    "# from psaw import PushshiftAPI\n",
    "from psycopg2.extras import Json\n",
    "from tqdm.auto import tqdm\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import requests\n",
    "import json\n",
    "import praw\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values, execute_batch\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "\n",
    "from reddit_stuff import backfill_submissions\n",
    "\n",
    "if \"insert_all_comments_to_db_pmaw\" in locals(): \n",
    "    del insert_all_comments_to_db_pmaw\n",
    "\n",
    "from reddit_stuff import insert_all_comments_to_db_pmaw\n",
    "\n",
    "# import spacy\n",
    "# from spacymoji import Emoji\n",
    "# from spacy import displacy\n",
    "\n",
    "pmaw_api = PushshiftAPI()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T20:35:17.696326Z",
     "start_time": "2021-07-11T20:35:17.688292Z"
    },
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Conn \n",
    "if \"get_conn\" in locals():\n",
    "    del get_conn\n",
    "    \n",
    "def get_conn() -> psycopg2.connect:\n",
    "    return psycopg2.connect(\n",
    "        dbname=\"polygonio\", \n",
    "        port=\"5433\", \n",
    "        host=\"localhost\", \n",
    "        password='rogerthat', \n",
    "        user=\"postgres\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-04T13:55:20.564019Z",
     "start_time": "2021-06-04T13:55:20.549459Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT 1;\"\n",
    "with get_conn() as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(query)\n",
    "        res = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get all comments from pmaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T17:24:56.786362Z",
     "start_time": "2021-06-26T17:24:56.772353Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if \"get_unique_col_from_db\" in locals(): \n",
    "    del get_unique_col_from_db\n",
    "    \n",
    "def get_unique_col_from_db(colname:str) -> list: \n",
    "    with get_conn() as conn: \n",
    "        with conn.cursor() as cur:\n",
    "            query = f\"SELECT DISTINCT({colname}) FROM wsb_comments;\"\n",
    "            cur.execute(query)\n",
    "            results = cur.fetchall()\n",
    "    results = [i[0] for i in results]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T17:26:29.591480Z",
     "start_time": "2021-06-26T17:26:25.110513Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_submission_ids = get_unique_col_from_db(colname=\"submission_id\")\n",
    "all_comment_ids_in_db = get_unique_col_from_db(colname=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T17:12:42.569853Z",
     "start_time": "2021-06-26T17:12:42.559810Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# submission_comments = pd.read_csv(\"all_submissions_and_comments.csv\", index_col=0)\n",
    "# submission_comments.loc[:, \"comments\"] = submission_comments[\"comments\"].apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\"))[\"data\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T17:58:26.358362Z",
     "start_time": "2021-06-26T17:42:22.250083Z"
    },
    "code_folding": [
     2
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission_id_comments = {}\n",
    "for submission_id in tqdm(all_submission_ids):\n",
    "    submission_id_comments[submission_id] = pmaw_api.search_submission_comment_ids(\n",
    "        ids=[submission_id], \n",
    "        safe_exit=True, \n",
    "        memsafe=True\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T18:01:07.937320Z",
     "start_time": "2021-06-26T18:01:05.461490Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission_id_comments_to_df = []\n",
    "for submission_id, comments in tqdm(submission_id_comments.items()):\n",
    "    submission_id_comments_to_df.append({\"submission_id\": submission_id, \"comments\": [comment for comment in comments]})\n",
    "    \n",
    "submission_comments = pd.DataFrame(submission_id_comments_to_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T18:24:38.662644Z",
     "start_time": "2021-06-26T18:01:53.045492Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_comments = []\n",
    "for sub_id in tqdm(submission_comments.submission_id):\n",
    "    comments = submission_comments.loc[submission_comments.submission_id == sub_id, \"comments\"].values[0]\n",
    "    comments_arr = pmaw_api.search_comments(ids=comments)\n",
    "    for c in comments_arr:\n",
    "        c[\"submission_id\"] = sub_id\n",
    "        all_comments.append(c)\n",
    "        \n",
    "comments_df = pd.DataFrame(all_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T18:28:56.430816Z",
     "start_time": "2021-06-26T18:26:37.474928Z"
    },
    "code_folding": [
     27
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "to_insert_comments = []\n",
    "for i in tqdm(range(len(comments_df))):\n",
    "    comment = comments_df.iloc[i, ].to_dict()\n",
    "    _ = comment.pop(\"media_metadata\")\n",
    "    comment[\"subreddit_name_prefixed\"] = f\"r/{comment['subreddit']}\"\n",
    "    _ = comment.pop(\"subreddit\")\n",
    "\n",
    "    for key, val in comment.items():\n",
    "        if key in [\"awarders\", \"user_reports\", \"all_awardings\", \"report_reasons\", \"gildings\",\n",
    "                   \"author_flair_richtext\", \"treatment_tags\", \"mod_reports\"]:\n",
    "            comment[key] = Json(json.dumps(val))\n",
    "            \n",
    "        if isinstance(comment[key], np.bool_):\n",
    "            comment[key] = bool(val)\n",
    "            \n",
    "        if isinstance(comment[key], np.int64):\n",
    "            comment[key] = int(val)\n",
    "\n",
    "    if isinstance(comment[\"edited\"], bool):\n",
    "        comment[\"edited\"] = 0\n",
    "        \n",
    "    if isinstance(comment[\"author_patreon_flair\"], bool):\n",
    "        comment[\"author_patreon_flair\"] = \"\"\n",
    "        \n",
    "    if isinstance(comment[\"author_cakeday\"], np.float): \n",
    "        comment[\"author_cakeday\"] = bool(0)\n",
    "        \n",
    "    if isinstance(comment[\"author_premium\"], np.float): \n",
    "        comment[\"author_premium\"] = bool(0)\n",
    "\n",
    "    cols_str = ','.join(comment.keys())\n",
    "    values_str = ('%s,' * len(comment)).rstrip(',')\n",
    "    insert_query = f\"\"\"INSERT INTO wsb_comments ({cols_str}) VALUES ({values_str}) ON CONFLICT (id) DO NOTHING;\"\"\"\n",
    "    to_insert_comments.append(tuple(comment.values()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T18:33:32.984814Z",
     "start_time": "2021-06-26T18:33:32.981838Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "insert_query = f\"INSERT INTO wsb_comments ({cols_str}) VALUES %s ON CONFLICT (id) DO NOTHING;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T18:59:25.861052Z",
     "start_time": "2021-06-26T18:34:25.169109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with get_conn() as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        try:\n",
    "            execute_values(cur, insert_query, to_insert_comments)\n",
    "            conn.commit()\n",
    "#             mogrified_query = cur.mogrify(insert_query, tuple(comment.values()))\n",
    "#             cur.execute(mogrified_query)\n",
    "        except psycopg2.errors.ProgrammingError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T20:05:47.908209Z",
     "start_time": "2021-06-26T20:05:45.609132Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with get_conn() as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SELECT t.submission_ids_completed FROM wsb_comments_status t ORDER BY t.insert_date DESC LIMIT 1;\")\n",
    "        all_submission_ids_completed = cur.fetchall()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some submission id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T10:40:58.300148Z",
     "start_time": "2021-08-16T10:40:58.171126Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T10:45:08.910217Z",
     "start_time": "2021-08-16T10:44:56.261383Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://api.polygon.io/v3/reference/tickers\"\n",
    "\n",
    "resp = requests.get(url, params={\n",
    "    \"active\": \"true\", \n",
    "    \"limit\": 1000, \n",
    "    \"apikey\": \"UPUKTfaMrhV1k5ZyCvBUbv_1pAjZ24zkUbLD_T\"\n",
    "})\n",
    "\n",
    "all_data = []\n",
    "data = resp.json()\n",
    "while \"next_url\" in data.keys():\n",
    "    resp = requests.get(data[\"next_url\"], params={\"apikey\": \"UPUKTfaMrhV1k5ZyCvBUbv_1pAjZ24zkUbLD_T\", \"limit\": 1000})\n",
    "    data = resp.json()\n",
    "    all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T14:42:39.524686Z",
     "start_time": "2021-08-16T14:42:39.520689Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T14:21:41.410170Z",
     "start_time": "2021-08-16T14:21:41.397750Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = px.data.stocks(indexed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-16T14:21:43.297054Z",
     "start_time": "2021-08-16T14:21:43.271502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>company</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>FB</th>\n",
       "      <th>NFLX</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>1.018172</td>\n",
       "      <td>1.011943</td>\n",
       "      <td>1.061881</td>\n",
       "      <td>0.959968</td>\n",
       "      <td>1.053526</td>\n",
       "      <td>1.015988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-15</th>\n",
       "      <td>1.032008</td>\n",
       "      <td>1.019771</td>\n",
       "      <td>1.053240</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>1.049860</td>\n",
       "      <td>1.020524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-22</th>\n",
       "      <td>1.066783</td>\n",
       "      <td>0.980057</td>\n",
       "      <td>1.140676</td>\n",
       "      <td>1.016858</td>\n",
       "      <td>1.307681</td>\n",
       "      <td>1.066561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-29</th>\n",
       "      <td>1.008773</td>\n",
       "      <td>0.917143</td>\n",
       "      <td>1.163374</td>\n",
       "      <td>1.018357</td>\n",
       "      <td>1.273537</td>\n",
       "      <td>1.040708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>1.216280</td>\n",
       "      <td>1.546914</td>\n",
       "      <td>1.425061</td>\n",
       "      <td>1.075997</td>\n",
       "      <td>1.463641</td>\n",
       "      <td>1.720717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09</th>\n",
       "      <td>1.222821</td>\n",
       "      <td>1.572286</td>\n",
       "      <td>1.432660</td>\n",
       "      <td>1.038855</td>\n",
       "      <td>1.421496</td>\n",
       "      <td>1.752239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16</th>\n",
       "      <td>1.224418</td>\n",
       "      <td>1.596800</td>\n",
       "      <td>1.453455</td>\n",
       "      <td>1.104094</td>\n",
       "      <td>1.604362</td>\n",
       "      <td>1.784896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>1.226504</td>\n",
       "      <td>1.656000</td>\n",
       "      <td>1.521226</td>\n",
       "      <td>1.113728</td>\n",
       "      <td>1.567170</td>\n",
       "      <td>1.802472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>1.213014</td>\n",
       "      <td>1.678000</td>\n",
       "      <td>1.503360</td>\n",
       "      <td>1.098475</td>\n",
       "      <td>1.540883</td>\n",
       "      <td>1.788185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "company         GOOG      AAPL      AMZN        FB      NFLX      MSFT\n",
       "date                                                                  \n",
       "2018-01-01  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "2018-01-08  1.018172  1.011943  1.061881  0.959968  1.053526  1.015988\n",
       "2018-01-15  1.032008  1.019771  1.053240  0.970243  1.049860  1.020524\n",
       "2018-01-22  1.066783  0.980057  1.140676  1.016858  1.307681  1.066561\n",
       "2018-01-29  1.008773  0.917143  1.163374  1.018357  1.273537  1.040708\n",
       "...              ...       ...       ...       ...       ...       ...\n",
       "2019-12-02  1.216280  1.546914  1.425061  1.075997  1.463641  1.720717\n",
       "2019-12-09  1.222821  1.572286  1.432660  1.038855  1.421496  1.752239\n",
       "2019-12-16  1.224418  1.596800  1.453455  1.104094  1.604362  1.784896\n",
       "2019-12-23  1.226504  1.656000  1.521226  1.113728  1.567170  1.802472\n",
       "2019-12-30  1.213014  1.678000  1.503360  1.098475  1.540883  1.788185\n",
       "\n",
       "[105 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T20:36:45.494057Z",
     "start_time": "2021-07-11T20:35:26.071436Z"
    }
   },
   "outputs": [],
   "source": [
    "posts = pmaw_api.search_submissions(q=\"Daily Discussion Thread\", subreddit=\"wallstreetbets\", limit=5000)\n",
    "submissions = [s for s in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T21:28:57.435239Z",
     "start_time": "2021-07-11T21:28:57.421239Z"
    }
   },
   "outputs": [],
   "source": [
    "len(submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-11T21:40:27.544162Z",
     "start_time": "2021-07-11T21:40:27.365164Z"
    }
   },
   "outputs": [],
   "source": [
    "exceptions = []\n",
    "all_dates_gathered = []\n",
    "for sub in tqdm(submissions):\n",
    "    if \"link_flair_text\" in sub.keys():\n",
    "        if sub[\"link_flair_text\"] == 'Daily Discussion':\n",
    "            try:\n",
    "                date_info = pd.to_datetime('-'.join( sub[\"full_link\"].split(\"/\")[-2].split(\"_\")[-4:][1:]), format=\"%B-%d-%Y\")\n",
    "                all_dates_gathered.append({\"date\": date_info, \"sub_links\": []})\n",
    "            except (TypeError, ValueError) as e: \n",
    "                print(e)\n",
    "                exceptions.append(sub)\n",
    "        else: \n",
    "            pass\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T15:34:47.024233Z",
     "start_time": "2021-07-09T15:33:19.361059Z"
    }
   },
   "outputs": [],
   "source": [
    "final_dates_gathered = []\n",
    "for sub in tqdm(submissions):\n",
    "    if \"link_flair_text\" in sub.keys():\n",
    "        if sub[\"link_flair_text\"] == 'Daily Discussion':\n",
    "            try:\n",
    "                date_info = pd.to_datetime('-'.join(sub[\"full_link\"].split(\"/\")[-2].split(\"_\")[-4:][1:]), format=\"%B-%d-%Y\")\n",
    "                for ele in all_dates_gathered:\n",
    "                    if ele[\"date\"] == date_info: \n",
    "                        ele[\"sub_links\"].append(sub[\"full_link\"])\n",
    "                        final_dates_gathered.append(ele)\n",
    "\n",
    "            except (TypeError, ValueError, AssertionError) as e:\n",
    "                exceptions.append(date_info)\n",
    "        else: \n",
    "            pass\n",
    "    else: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T15:34:47.024233Z",
     "start_time": "2021-07-09T15:33:19.361059Z"
    }
   },
   "outputs": [],
   "source": [
    "all_submissions_meta_df = pd.DataFrame(final_dates_gathered)\n",
    "all_submissions_meta_df.drop_duplicates(subset=[\"date\"], inplace=True)\n",
    "all_submissions_meta_df.reset_index(drop=True, inplace=True)\n",
    "all_submissions_meta_df.set_index(\"date\", inplace=True)\n",
    "all_submissions_meta_df = all_submissions_meta_df.explode(\"sub_links\")\n",
    "all_submissions_meta_df = all_submissions_meta_df.reset_index()\n",
    "all_submissions_meta_df.columns = [\"date\", \"links_in_reddit\"]\n",
    "\n",
    "### Check if these are present in the database, and how many comments do each of these submissions have?\n",
    "with get_conn() as conn: \n",
    "    with conn.cursor() as cur: \n",
    "        cur.execute(\"SELECT DISTINCT id, full_link FROM wsb_submissions WHERE link_flair_text = 'Daily Discussion';\")\n",
    "        sub_in_db_df = pd.DataFrame(cur.fetchall(), columns=[\"id\", \"links_in_db\"])\n",
    "\n",
    "merged_df = pd.merge(left=all_submissions_meta_df, right=sub_in_db_df, left_on=\"links_in_reddit\", right_on=\"links_in_db\", how=\"outer\")\n",
    "in_db_not_daily_subs_df = merged_df[merged_df[\"date\"].isna()].copy()\n",
    "in_db_possible_backup_needed_df = merged_df[~merged_df[\"date\"].isna()].copy()\n",
    "in_db_possible_backup_needed_df = in_db_possible_backup_needed_df.sort_values(by=\"date\")\n",
    "in_db_possible_backup_needed_df = in_db_possible_backup_needed_df.reset_index(drop=True)\n",
    "\n",
    "# Grab the submissions that are not there in db and push them\n",
    "submission_links_not_uploaded = \\\n",
    "set(in_db_possible_backup_needed_df[\"links_in_reddit\"].values.tolist()) - \\\n",
    "set(in_db_possible_backup_needed_df[\"links_in_db\"].values.tolist())\n",
    "\n",
    "submission_ids = [ele.split(\"/\")[6] for ele in submission_links_not_uploaded]\n",
    "\n",
    "backfill_submissions(capture_exceptions=False, to_be_refreshed=submission_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T15:47:47.338386Z",
     "start_time": "2021-07-09T15:47:26.996766Z"
    }
   },
   "outputs": [],
   "source": [
    "all_comments_df = []\n",
    "for sub_id in tqdm(submission_ids):\n",
    "    comments = pmaw_api.search_submission_comment_ids(\n",
    "        ids=[sub_id], safe_exit=True, memsafe=True\n",
    "    )\n",
    "    \n",
    "    submission_id_comments = {\n",
    "    \"submission_id\": sub_id,\n",
    "    \"comments\": [comment for comment in comments],\n",
    "    }\n",
    "\n",
    "    all_comments = []\n",
    "    comments_arr = pmaw_api.search_comments(ids=submission_id_comments[\"comments\"])\n",
    "    for c in tqdm(comments_arr, leave=False):\n",
    "        c[\"submission_id\"] = submission_id_comments[\"submission_id\"]\n",
    "        all_comments.append(c)\n",
    "\n",
    "    comments_df = pd.DataFrame(all_comments)\n",
    "    all_comments_df.append(comments_df)\n",
    "    \n",
    "all_comments_df = pd.concat(all_comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T16:00:27.063812Z",
     "start_time": "2021-07-09T15:59:17.260679Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_comments_df.iloc[0,].to_dict()\n",
    "# insert_all_comments_to_db_pmaw(df=all_comments_df)\n",
    "# update_wsb_comments_status_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figure out a way to count number of comments in each submission\n",
    "## - After each day's insert, make a new table called wsb_comments_diff, which contains date, diff between wsb_comments_tickers/analytics\n",
    "## - Make a function that will download the difference between the tickers/analytics and create the new bunch of \"prepared_statements\" and will \n",
    "## - Make a view where each submission has it's own submission count with cols = submission_id, no_of_comments\n",
    "## - Make a smaller table wsb_comments_analytics : contains processed information where each comment_id has it's own ticker info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_conn() as conn: \n",
    "    with conn.cursor() as cur: \n",
    "        cur.execute(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_schema='public' aND table_name='wsb_comments_tickers');\")\n",
    "        wsb_comments_tickers_exists = cur.fetchall()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T13:49:40.549293Z",
     "start_time": "2021-07-10T13:41:12.686429Z"
    }
   },
   "outputs": [],
   "source": [
    "### Check if these are present in the database, and how many comments do each of these submissions have?\n",
    "with get_conn() as conn: \n",
    "    with conn.cursor() as cur: \n",
    "        cur.execute(\"SELECT created_utc::date as date, submission_id, comment_id FROM wsb_comments_analytics;\")\n",
    "        com_sub_df = pd.DataFrame(cur.fetchall(), columns=[\"date\", \"submission_id\", \"comment_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T16:10:57.311570Z",
     "start_time": "2021-07-10T16:10:36.828574Z"
    }
   },
   "outputs": [],
   "source": [
    "agg_df = pd.DataFrame(com_sub_df.groupby([\"date\", \"submission_id\"])[\"comment_id\"].nunique())\n",
    "agg_df = agg_df.sort_index(ascending=True)\n",
    "agg_df = agg_df.reset_index()\n",
    "agg_df = agg_df.groupby([\"date\"]).apply(lambda x: x.sort_values(by=\"comment_id\", ascending=False).max()).drop(columns=[\"date\"])\n",
    "agg_df.index = pd.to_datetime(agg_df.index)\n",
    "agg_df[\"comment_id\"].plot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:46:15.914276Z",
     "start_time": "2021-07-10T15:46:15.890305Z"
    }
   },
   "outputs": [],
   "source": [
    "### Over the last 3 months, \n",
    "all_business_weeks = pd.period_range(start=agg_df.index[0], end=agg_df.index[-1], freq=\"W\")\n",
    "\n",
    "all_dates_not_present = []\n",
    "all_submission_ids_to_update = []\n",
    "for i in tqdm(range(len(all_business_weeks))):\n",
    "    date_fmt = \"%Y-%m-%d\"\n",
    "    bweek = all_business_weeks[i]\n",
    "    df_ = agg_df.loc[bweek.start_time: bweek.end_time]\n",
    "    dates_present = [d for d in pd.to_datetime(df_.index.values)]\n",
    "    \n",
    "    dates_not_present = [pd.to_datetime(x) for x in \n",
    "                         pd.bdate_range(start=bweek.start_time, end=bweek.end_time) \n",
    "                         if x not in dates_present]\n",
    "    \n",
    "    ### Which dates are missing?\n",
    "    all_dates_not_present += dates_not_present\n",
    "\n",
    "    ### Grab all submission id's that are < -50% of the mean comment_id number \n",
    "    relative_df = ( (df_.comment_id - df_.comment_id.max() )/ df_.comment_id.max() ) * 100\n",
    "    all_submission_ids_to_update += df_.loc[relative_df[relative_df < -50].index, \"submission_id\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T19:19:33.774322Z",
     "start_time": "2021-07-10T18:06:18.195057Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_id_exceptions = backfill_submissions(capture_exceptions=True, to_be_refreshed=all_submission_ids_to_update)\n",
    "\n",
    "sub_id_exceptions = pd.concat(sub_id_exceptions)\n",
    "\n",
    "sub_id_exceptions.to_csv(\"sub_id_exceptions.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T19:20:47.774746Z",
     "start_time": "2021-07-10T19:20:44.390625Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_id_exceptions = pd.concat(sub_id_exceptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T19:40:24.076880Z",
     "start_time": "2021-07-10T19:40:10.528479Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_id_exceptions.to_csv(\"sub_id_exceptions.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T19:41:04.401083Z",
     "start_time": "2021-07-10T19:40:59.967050Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_id_exceptions = pd.read_csv(\"sub_id_exceptions.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T19:44:20.460570Z",
     "start_time": "2021-07-10T19:41:08.047702Z"
    }
   },
   "outputs": [],
   "source": [
    "insert_all_comments_to_db_pmaw(sub_id_exceptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot WOW counts\n",
    "# fig, ax = plt.subplots()\n",
    "# my_dt_fmt = DateFormatter(\"%Y-%m-%d\")\n",
    "# ax.xaxis.set_major_formatter(my_dt_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For all the links in db, count the number of comments in each of them\n",
    "# prepared_statements_df = pd.read_csv(\"prepared_statements.csv\")\n",
    "# prepared_statements_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true
   },
   "source": [
    "### Get some praw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from reddit_stuff import get_reddit_client\n",
    "r_client = get_reddit_client()\n",
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submissions = api.search_submissions(\n",
    "    search_window=5, \n",
    "    max_ids_per_request=1000,\n",
    "    safe_exit=True, \n",
    "    max_results_per_request=100, \n",
    "    subreddit=\"wallstreetbets\"\n",
    ")\n",
    "\n",
    "all_submissions = [post for post in submissions]\n",
    "\n",
    "all_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "json.dumps(all_submissions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open(\"submissions.txt\", \"w\") as f:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_epoch = int(datetime.datetime(2019, 1, 1).timestamp())\n",
    "submissions = api.search_submissions(after=start_epoch, subreddit=\"wallstreetbets\", limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pushshift_host = \"https://api.pushshift.io/reddit/submission/comment_ids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_submissions = []\n",
    "for sub_id in tqdm(submissions):\n",
    "    all_submissions.append(sub_id)\n",
    "#     response = requests.get(f\"{pushshift_host}/{sub_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f\"{pushshift_host}/{sub_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sub_id.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_urls = []\n",
    "all_comment_ids = []\n",
    "all_submissions_without_comments = []\n",
    "for sub_id in tqdm(all_submissions):\n",
    "    all_urls.append(f\"{pushshift_host}/{sub_id.id}\")\n",
    "    \n",
    "#     response = requests.get(f\"{pushshift_host}/{sub_id.id}\")\n",
    "#     if response.status_code == 200:\n",
    "#         data = response.json()[\"data\"]\n",
    "        \n",
    "#         if len(data) > 0:\n",
    "#             all_comment_ids.append(data)\n",
    "#         else:\n",
    "#             all_submissions_without_comments.append(sub_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if \"get_comment_ids\" in locals():\n",
    "    del get_comment_ids\n",
    "    \n",
    "def get_comment_ids(url:str):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T17:13:38.746769Z",
     "start_time": "2021-06-03T17:13:37.357559Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT id, created_utc, parent_id, body from wsb_comments;\"\n",
    "with get_conn() as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(query)\n",
    "        res = cur.fetchall()\n",
    "        \n",
    "df = pd.DataFrame.from_records(res, columns=[\"id\", \"created_utc\", \"parent_id\", \"body\"])\n",
    "\n",
    "df = df.set_index(\"id\")\n",
    "df = df.sort_values(by=[\"created_utc\"])\n",
    "df[\"created_utc_datetime\"] = df[\"created_utc\"].apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "df = df.drop(columns=[\"created_utc\"], inplace=False)\n",
    "df = df[[\"created_utc_datetime\", \"parent_id\", \"body\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T17:14:46.520340Z",
     "start_time": "2021-06-03T17:14:46.497909Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T17:15:33.241026Z",
     "start_time": "2021-06-03T17:15:33.197029Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"created_utc_datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T17:27:31.566530Z",
     "start_time": "2021-06-03T17:27:31.504546Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_trf')\n",
    "# emoji = Emoji(nlp)\n",
    "nlp.add_pipe(\"emoji\", first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T19:53:57.738185Z",
     "start_time": "2021-06-03T19:53:57.725225Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def clean_article(text:str) -> str:\n",
    "    return text.replace(\"\\n\\n\", \" \").replace(\"\\n\", \" \").replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T18:53:52.542246Z",
     "start_time": "2021-06-03T18:53:52.481240Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 5\n",
    "text = clean_article(text=df.iloc[i, 2])\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Time to rename all tickers as TKR - Use new NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T18:51:36.066653Z",
     "start_time": "2021-06-03T18:51:35.985297Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query_2 = \"SELECT ticker, name, market from ticker_vxes;\"\n",
    "\n",
    "with get_conn() as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(query_2)\n",
    "        tickers_res = cur.fetchall()\n",
    "        \n",
    "tickers_df = pd.DataFrame.from_records(tickers_res, columns=[\"ticker\", \"name\", \"market\"])\n",
    "tickers_df = tickers_df[tickers_df[\"market\"] == \"stocks\"]\n",
    "tickers_df = tickers_df.sort_values(by=\"ticker\")\n",
    "\n",
    "tickers_df = tickers_df.reset_index(drop=True)\n",
    "tickers_df = tickers_df.iloc[2: ]\n",
    "\n",
    "tickers = tickers_df[\"ticker\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Create training data for the new NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T19:22:02.697295Z",
     "start_time": "2021-06-03T19:22:01.911800Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T19:23:32.330531Z",
     "start_time": "2021-06-03T19:23:32.218120Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T20:18:48.737933Z",
     "start_time": "2021-06-03T20:18:48.717570Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if \"find_ner_and_insert_into_db\" in locals():\n",
    "    del find_ner_and_insert_into_db\n",
    "    \n",
    "def find_ner_and_insert_into_db(index:str, text:str): \n",
    "    text = clean_article(text=text)\n",
    "    it = {text: {\"entities\": []}}\n",
    "    \n",
    "    for word in text.split(\" \"):\n",
    "        word = word.replace(\".\", \" \").replace(\"'\", \"\").upper()\n",
    "        if word in tickers:\n",
    "            it[text][\"entities\"] += [(m.start(), m.end(), \"TKR\") for m in re.finditer(word, text)]\n",
    "                \n",
    "    insert_query = \\\n",
    "    f\"\"\"INSERT INTO wsb_comments_ner(id, ner_labels) VALUES ('{index}', array['{json.dumps(it)}']::json[]) ON CONFLICT (id) DO UPDATE SET ner_labels = EXCLUDED.ner_labels;\"\"\"\n",
    "    with get_conn() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(insert_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T20:18:55.930943Z",
     "start_time": "2021-06-03T20:18:55.694912Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_ = train_df[\"body\"].reset_index()\n",
    "tasks = [(index, text) for index, text in df_.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T20:16:59.553179Z",
     "start_time": "2021-06-03T20:16:59.538177Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-03T20:19:05.459Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with Pool(processes=os.cpu_count() - 2) as pool:\n",
    "    for _ in tqdm.tqdm(pool.imap_unordered(find_ner_and_insert_into_db, tasks), total=len(tasks)):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T20:02:09.203249Z",
     "start_time": "2021-06-03T19:54:55.093367Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TRAIN_DATA = [\n",
    "#     (\"Who is Shaka Khan?\", {\"entities\": [(7, 17, \"PERSON\")]}),\n",
    "#     (\"I like London and Berlin.\", {\"entities\": [(7, 13, \"LOC\"), (18, 24, \"LOC\")]}),\n",
    "# ]\n",
    "\n",
    "# TRAIN_DATA = []\n",
    "\n",
    "# for i in tqdm(range(len(train_df[[\"body\"]]))):\n",
    "#     text = clean_article(text=train_df.iloc[i, 2])\n",
    "#     index = train_df.index[i]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38-env",
   "language": "python",
   "name": "py38-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
